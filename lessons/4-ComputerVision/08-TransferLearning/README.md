# 预训练网络和迁移学习

训练卷积神经网络可以花费很多时间，并且需要大量数据。然而，大部分时间都用于学习网络可以用来从图像中提取模式的最佳低级过滤器。一个自然的问题出现了 - 可以将在一个数据集上训练的神经网络适应于分类不同图像，而不需要进行完整的训练过程吗？

## [课前测验](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/108)

这种方法被称为**迁移学习**，因为我们将一些知识从一个神经网络模型转移到另一个模型中。在迁移学习中，我们通常从一个预训练的模型开始，该模型已经在一些大型图像数据集（例如**ImageNet**）上进行了训练。这些模型已经能够很好地从通用图像中提取不同的特征，而在许多情况下，仅构建一个基于这些提取特征的分类器就能获得良好的结果。

> ✅ 迁移学习是一个在其他学术领域中也可找到的术语，比如教育。它指的是将从一个领域获取的知识应用于另一个领域的过程。

## 作为特征提取器的预训练模型

在前一节中我们提到，卷积网络由许多层组成，每一层都应该从图像中提取一些特征，从低级像素组合（例如水平/垂直线或笔画）到更高级的特征组合，对应于一些东西的眼睛（如火焰的眼睛）。如果我们在足够大的通用和多样化的图像数据集上训练卷积神经网络，网络应该能够学习提取这些常见的特征。

Keras和PyTorch都包含一些函数，可以方便地加载用于一些常见架构的预训练神经网络权重，其中大部分是在ImageNet图像上训练的。最常用的模型在上一课的[CNN架构](../07-ConvNets/CNN_Architectures.md)页面中有描述。特别是，你可以考虑使用以下之一：

* **VGG-16 / VGG-19**是相对简单的模型，但仍然具有较高的准确性。通常使用VGG作为第一次尝试是一个不错的选择，可以看看迁移学习的效果如何。
* **ResNet**是Microsoft Research在2015年提出的一系列模型。它们有更多的层，因此需要更多的资源。
* **MobileNet**是一系列尺寸较小的模型，适用于移动设备。如果你的资源有限并且可以牺牲一点准确性的话，可以使用它们。以下是VGG-16网络从一张猫的图片中提取出来的特征示例：

![由VGG-16提取的特征](images/features.png)

## 猫和狗数据集

在本例中，我们将使用一个名为[猫和狗](https://www.microsoft.com/download/details.aspx?id=54765&WT.mc_id=academic-77998-cacaste)的数据集，该数据集非常接近于一个真实的图像分类场景。

## ✍️ 练习：迁移学习让我们在相应的笔记本中看一下迁移学习的实际应用：

* [迁移学习 - PyTorch](TransferLearningPyTorch.ipynb)
* [迁移学习 - TensorFlow](TransferLearningTF.ipynb)

## 可视化对抗性猫

预训练的神经网络中包含了不同的模式，包括理想的猫（以及理想的狗、理想的斑马等）。有趣的是，我们可以尝试**可视化这个图像**。然而，这并不简单，因为模式遍布在网络权重中，而且以层次结构组织。

我们可以采用一种方法，从随机图像开始，然后尝试使用**梯度下降优化**技术来调整图像，以便网络开始认为它是一只猫。![图像优化循环](images/ideal-cat-loop.png)

然而，如果我们这样做，我们会得到一个非常类似于随机噪声的东西。这是因为*有很多种方法可以让网络认为输入图像是一只猫*，包括一些在视觉上没有意义的方法。虽然这些图像包含了许多典型猫的图案，但没有任何约束使它们在视觉上有区别。

为了改善结果，我们可以将另一个术语添加到损失函数中，该术语称为**变化损失**。它是一个指标，显示图像相邻像素之间的相似程度。最小化变化损失会使图像更平滑，并消除噪声-从而显示出更具吸引力的图案。以下是这样的"理想"图像的示例，这些图像以高概率被分类为猫和斑马：

![理想猫](images/ideal-cat.png) | ![理想斑马](images/ideal-zebra.png)
-----|-----
 *理想猫* | *理想斑马*可以使用类似的方法对神经网络进行所谓的**对抗攻击**。假设我们想欺骗一个神经网络，让一只狗看起来像是一只猫。如果我们拿到一只被网络识别为狗的狗的图片，然后使用梯度下降优化来微调这个图片，直到网络开始将其分类为猫:

![一只狗的图片](images/original-dog.png) | ![被分为猫的狗的图片](images/adversarial-dog.png)
-----|-----
*原始的一只狗的图片* | *被分类为猫的狗的图片*

查看在以下笔记本中复制以上结果的代码:

* [理想和对抗猫 - TensorFlow](AdversarialCat_TF.ipynb)
* ## 结论

使用迁移学习，你可以快速地构建一个用于自定义对象分类任务的分类器，并且达到较高的准确率。你可以看到，我们现在正在解决的更复杂的任务需要更高的计算能力，无法在CPU上轻松解决。在下一个单元中，我们将尝试使用更轻量级的实现来使用较低的计算资源训练相同的模型，这将导致稍微降低准确率。

## 🚀挑战

在附带的笔记本中，底部有关于迁移学习最适合相似训练数据（也许是一种新类型的动物）的说明。尝试用全新类型的图片进行一些实验，看看你的迁移学习模型表现得如何好或差。

## [讲后测验](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/208)

## 复习和自学

阅读[TrainingTricks.md](TrainingTricks.md)来加深你对其他训练模型的方式的了解。

## [作业](lab/README.md)

在这个实验室中，我们将使用真实的 [Oxford-IIIT](https://www.robots.ox.ac.uk/~vgg/data/pets/) 宠物数据集，其中包含35种猫和狗的品种，并且我们将构建一个迁移学习分类器。