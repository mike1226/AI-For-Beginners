# 生成对抗网络

在前面一节中，我们学习了关于**生成模型**的知识：能够生成类似于训练数据集中的新图像的模型。VAE是一个很好的生成模型的例子。

## [课前测验](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/110)

然而，如果我们尝试使用VAE生成一些有意义的东西，比如合理分辨率的绘画作品，我们会发现训练并不很好地收敛。对于这种情况，我们应该了解另一种专门针对生成模型的架构 - **生成对抗网络**，或GAN。

GAN的主要思想是有两个神经网络彼此训练：<img src="images/gan_architecture.png" width="70%"/>

> 图片由[Dmitry Soshnikov](http://soshnikov.com)提供

> ✅ 一些词汇:
> * **生成器 (Generator)** 是一些随机向量为输入的网络，并以图像作为结果生成。
> * **判别器 (Discriminator)** 是图像为输入的网络，并应该告诉我们这张图像是来自训练数据集的真实图像，还是由生成器生成的图像。本质上它就是一个图像分类器。

### 判别器 (Discriminator)

鉴别器的架构与普通的图像分类网络没有区别。在最简单的情况下，它可以是一个全连接分类器，但最可能的情况是一个卷积网络。在最简单的情况下，它可以是一个全连接分类器，但更可能的是它将是一个[卷积网络](../07-ConvNets/README.md)。


✅ 基于卷积网络的GAN被称为[DCGAN](https://arxiv.org/pdf/1511.06434.pdf)。

CNN鉴别器由以下层组成：多个卷积+池化层（空间尺寸逐渐减小），一个或多个全连接层，以获取“特征向量”，最后是二元分类器。

✅ 在这个上下文中，“池化”是一种减小图像尺寸的技术。“池化层通过将一个层中的神经元簇的输出组合成下一层中的单个神经元来降低数据维度。”- [来源](https://wikipedia.org/wiki/Convolutional_neural_network#Pooling_layers)

### 生成器

生成器稍微有点复杂。你可以将其视为一个反向的判别器。它从潜在向量开始（代替特征向量），有一个全连接层将其转换为所需的大小/形状，然后是反卷积+上采样。这与[自编码器](../09-Autoencoders/README.md)的*解码器*部分类似。

> ✅ 因为卷积层是实现为线性滤波器遍历图像的，所以反卷积实质上类似于卷积，并且可以使用相同的层逻辑进行实现。

<img src="images/gan_arch_detail.png" width="70%"/>

> 图片来自[Dmitry Soshnikov](http://soshnikov.com)

### 训练GAN

模型GANs（生成对抗网络）被称为**对抗性**，因为生成器和判别器之间存在着持续的竞争。在这个竞争过程中，生成器和判别器都在改进，从而使网络学习如何生成越来越好的图片。

训练分为两个阶段:

* **训练判别器**。这个任务相当直观：我们通过生成器生成一批图片，并给它们打上标签0（代表假图片），然后从输入数据集中拿出一批图片（带有标签1，真实图片）。我们得到一些*判别器损失*，然后进行反向传播。
* **训练生成器**。这个稍微有些棘手，因为我们无法直接知道生成器的预期输出。我们将整个GAN网络包括一个生成器和一个判别器，用一些随机向量输入，并期望结果为1（对应真实图片）。然后我们冻结判别器的参数（我们不希望它在这个步骤中被训练），然后进行反向传播。

在这个过程中，生成器和判别器的损失都没有明显下降。理想的情况下，它们应该是振荡的，对应着两个网络提高性能的过程。

## ✍️ 练习: GANs
* [使用TensorFlow/Keras实现的GAN笔记本](GANTF.ipynb)
* [使用PyTorch实现的GAN笔记本](GANPyTorch.ipynb)

### GAN训练中的问题

GAN在训练过程中被认为特别难以训练。以下是一些问题：

* **模式坍塌**。这个术语指的是生成器学习只能产生一个成功欺骗判别器的图片，而不能生成多种不同的图片。
* **对超参数的敏感性**。经常会看到GAN根本无法收敛，然后突然减小学习率以达到收敛。* 在生成器和判别器之间保持**平衡**。在许多情况下，判别器损失可以很快降至零，这导致生成器无法进一步训练。为了解决这个问题，我们可以尝试为生成器和判别器设置不同的学习率，或者如果损失已经太低，则跳过判别器训练。
* 高分辨率的**训练**。与自动编码器一样，这个问题被触发是因为重建太多层卷积网络会导致伪影。这个问题通常通过所谓的**渐进增长**来解决，首先在低分辨率图像上训练几层，然后解锁或添加图层。另一种解决方案是在层之间添加额外的连接，同时训练多个分辨率 - 有关详细信息，请参阅《多尺度梯度GAN论文》。

## 风格转移

GAN是一种生成艺术图片的好方法。另一个有趣的技术是所谓的**风格转移**，它接受一个**内容图像**，并以不同的风格重新绘制它，应用来自**风格图像**的滤镜。

它的工作原理如下：
* 我们从一个随机噪声图像开始（或从一个内容图像开始，但为了理解起见，从随机噪声开始更容易）
* 我们的目标是创建一种图像，既接近内容图像，又接近风格图像。这将由两个损失函数决定：
   - **内容损失**是基于卷积神经网络从当前图像和内容图像中提取的特征进行计算的。
   - **风格损失**是以一种巧妙的方式使用Gram矩阵在当前图像和风格图像之间计算的（详细信息请参见[示例笔记本](StyleTransfer.ipynb)）。
* 为使图像更平滑并消除噪声，我们还引入了**变化损失**，它计算相邻像素之间的平均距离。
* 主要的优化循环使用梯度下降（或其他优化算法）调整当前图像，以最小化总损失，总损失是所有三种损失的加权和。

## ✍️ 示例：[风格迁移](StyleTransfer.ipynb)

## [课后测验](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/210)

## 结论

在本课程中，您学习了有关GAN（生成对抗网络）以及如何对其进行训练的内容。您还了解了这种类型的神经网络可能面临的特殊挑战，并掌握了如何应对这些挑战的一些策略。

## 🚀 挑战

通过使用自己的图像来运行[风格迁移笔记本](StyleTransfer.ipynb)。

## 复习和自学

为了更多参考，可以阅读以下资源以了解有关GAN的更多信息：* [Marco Pasini，我一年GAN训练的10个教训](https://towardsdatascience.com/10-lessons-i-learned-training-generative-adversarial-networks-gans-for-a-year-c9071159628)
* [StyleGAN](https://en.wikipedia.org/wiki/StyleGAN)，值得考虑的*事实上*的GAN架构
* [使用Azure ML上的GAN创建生成艺术](https://soshnikov.com/scienceart/creating-generative-art-using-gan-on-azureml/)

## 作业

重新访问与本课程相关的两个笔记本之一，并在自己的图像上重新训练GAN。你能创造出什么？